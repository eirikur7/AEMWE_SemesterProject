{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tbl3.csv\", skiprows=8)\n",
    "df.columns = ['X (m)', 'Y (m)', 'c_KOH (mol/m^3)', 'W_mem (m)', 'T (K)', 'E_cell (V)', 'I_density (A/m^2)']\n",
    "\n",
    "# Drop rows with NaN target\n",
    "df = df.dropna(subset=['I_density (A/m^2)'])\n",
    "\n",
    "# Input and output\n",
    "X = df[['X (m)', 'Y (m)', 'c_KOH (mol/m^3)', 'W_mem (m)', 'T (K)', 'E_cell (V)']].values\n",
    "y = df['I_density (A/m^2)'].values\n",
    "\n",
    "# Scale input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 4\n",
    "LAYER_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ebben\\anaconda3\\envs\\SemesterProject_AEMWE\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(LAYER_SIZE, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "for _ in range(NUM_LAYERS - 1):\n",
    "    model.add(Dense(LAYER_SIZE, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 12607664.0000 - mae: 947.7027 - val_loss: 651021.6250 - val_mae: 284.8624\n",
      "Epoch 2/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: 1117545.0000 - mae: 299.7551 - val_loss: 373162.7188 - val_mae: 212.9626\n",
      "Epoch 3/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 755043.8125 - mae: 243.0871 - val_loss: 1908728.1250 - val_mae: 285.5281\n",
      "Epoch 4/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 681406.6250 - mae: 203.1710 - val_loss: 244801.0156 - val_mae: 126.1436\n",
      "Epoch 5/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 522870.7188 - mae: 179.6163 - val_loss: 214708.0469 - val_mae: 125.1833\n",
      "Epoch 6/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 464683.8125 - mae: 165.1059 - val_loss: 491795.3438 - val_mae: 192.6607\n",
      "Epoch 7/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 400150.5000 - mae: 158.2847 - val_loss: 272650.5312 - val_mae: 174.2744\n",
      "Epoch 8/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 427688.8438 - mae: 159.4896 - val_loss: 134147.6875 - val_mae: 98.6548\n",
      "Epoch 9/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 331828.3750 - mae: 138.4469 - val_loss: 169670.2031 - val_mae: 124.8525\n",
      "Epoch 10/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 316968.8438 - mae: 131.0613 - val_loss: 158459.8125 - val_mae: 111.6486\n",
      "Epoch 11/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 265209.8750 - mae: 120.6492 - val_loss: 151770.3594 - val_mae: 102.6534\n",
      "Epoch 12/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - loss: 290838.0938 - mae: 113.3524 - val_loss: 121659.3750 - val_mae: 91.8049\n",
      "Epoch 13/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - loss: 268774.4375 - mae: 116.7172 - val_loss: 140809.5781 - val_mae: 92.5516\n",
      "Epoch 14/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3ms/step - loss: 198761.7656 - mae: 100.6612 - val_loss: 135139.4844 - val_mae: 81.0156\n",
      "Epoch 15/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - loss: 212561.0938 - mae: 103.5042 - val_loss: 156141.4219 - val_mae: 119.2187\n",
      "Epoch 16/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - loss: 218086.7656 - mae: 105.3807 - val_loss: 147422.8438 - val_mae: 79.0234\n",
      "Epoch 17/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 213573.1406 - mae: 101.9052 - val_loss: 135143.0469 - val_mae: 90.8364\n",
      "Epoch 18/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3ms/step - loss: 200869.6250 - mae: 99.9271 - val_loss: 128497.5234 - val_mae: 89.3373\n",
      "Epoch 19/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 191152.7188 - mae: 95.4539 - val_loss: 458296.3125 - val_mae: 156.3271\n",
      "Epoch 20/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 201649.5000 - mae: 95.4949 - val_loss: 142396.6406 - val_mae: 72.0622\n",
      "Epoch 21/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - loss: 193015.0938 - mae: 93.4813 - val_loss: 120598.3828 - val_mae: 68.8127\n",
      "Epoch 22/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 186751.8125 - mae: 92.6721 - val_loss: 117628.9297 - val_mae: 64.2433\n",
      "Epoch 23/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - loss: 170217.8594 - mae: 88.2987 - val_loss: 121050.9688 - val_mae: 67.9915\n",
      "Epoch 24/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 175150.3125 - mae: 86.7105 - val_loss: 117937.7422 - val_mae: 72.4462\n",
      "Epoch 25/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - loss: 186003.2656 - mae: 88.6635 - val_loss: 145966.0156 - val_mae: 86.3528\n",
      "Epoch 26/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - loss: 190746.1250 - mae: 89.3595 - val_loss: 135978.8594 - val_mae: 71.0479\n",
      "Epoch 27/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - loss: 166069.2188 - mae: 84.0236 - val_loss: 158472.3438 - val_mae: 77.6992\n",
      "Epoch 28/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 164389.5156 - mae: 82.5300 - val_loss: 116216.8594 - val_mae: 72.7638\n",
      "Epoch 29/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 181603.6250 - mae: 87.0410 - val_loss: 105249.0469 - val_mae: 71.2675\n",
      "Epoch 30/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - loss: 159751.7969 - mae: 80.8525 - val_loss: 105392.1875 - val_mae: 66.3719\n",
      "Epoch 31/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 168306.5312 - mae: 83.6737 - val_loss: 351776.2500 - val_mae: 111.0036\n",
      "Epoch 32/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - loss: 192156.2500 - mae: 84.4644 - val_loss: 239444.5938 - val_mae: 91.8532\n",
      "Epoch 33/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3ms/step - loss: 172705.1562 - mae: 82.7500 - val_loss: 144213.1406 - val_mae: 92.2268\n",
      "Epoch 34/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - loss: 152133.5781 - mae: 77.3699 - val_loss: 265504.8750 - val_mae: 96.3654\n",
      "Epoch 35/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3ms/step - loss: 157753.7969 - mae: 77.5184 - val_loss: 108010.7266 - val_mae: 61.6585\n",
      "Epoch 36/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - loss: 160666.2969 - mae: 81.7158 - val_loss: 190510.0156 - val_mae: 83.6054\n",
      "Epoch 37/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5ms/step - loss: 165165.3438 - mae: 78.9101 - val_loss: 193557.4375 - val_mae: 79.8559\n",
      "Epoch 38/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 5ms/step - loss: 154591.4062 - mae: 79.6391 - val_loss: 211731.7188 - val_mae: 101.0651\n",
      "Epoch 39/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 152577.8906 - mae: 78.6329 - val_loss: 136836.0156 - val_mae: 67.9454\n",
      "Epoch 40/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 151708.1406 - mae: 77.9780 - val_loss: 111930.5078 - val_mae: 70.0031\n",
      "Epoch 41/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - loss: 152264.3125 - mae: 77.4209 - val_loss: 169695.5938 - val_mae: 85.0417\n",
      "Epoch 42/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - loss: 149575.4844 - mae: 76.4294 - val_loss: 125884.7500 - val_mae: 69.4127\n",
      "Epoch 43/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - loss: 140290.9844 - mae: 75.0502 - val_loss: 121498.3281 - val_mae: 65.6121\n",
      "Epoch 44/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 151773.2969 - mae: 76.1370 - val_loss: 114959.2422 - val_mae: 70.1489\n",
      "Epoch 45/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 154560.1406 - mae: 77.1218 - val_loss: 105731.1719 - val_mae: 56.6714\n",
      "Epoch 46/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 157830.1094 - mae: 78.2176 - val_loss: 132339.3750 - val_mae: 61.5953\n",
      "Epoch 47/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 150324.7031 - mae: 74.6083 - val_loss: 112160.8281 - val_mae: 67.9042\n",
      "Epoch 48/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 146208.6406 - mae: 74.0687 - val_loss: 109952.0469 - val_mae: 62.3665\n",
      "Epoch 49/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 142265.7969 - mae: 73.9046 - val_loss: 134256.7344 - val_mae: 67.4464\n",
      "Epoch 50/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 134876.6875 - mae: 71.6268 - val_loss: 129425.1719 - val_mae: 60.5909\n",
      "Epoch 51/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 143622.2500 - mae: 73.2828 - val_loss: 160053.5625 - val_mae: 72.7736\n",
      "Epoch 52/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - loss: 140619.8438 - mae: 74.8478 - val_loss: 136235.0938 - val_mae: 77.4973\n",
      "Epoch 53/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 141543.7812 - mae: 71.8881 - val_loss: 110462.5000 - val_mae: 58.2051\n",
      "Epoch 54/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 131767.1250 - mae: 72.0635 - val_loss: 114090.6484 - val_mae: 59.0674\n",
      "Epoch 55/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 133453.5781 - mae: 71.0216 - val_loss: 113963.1562 - val_mae: 63.4274\n",
      "Epoch 56/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 134348.4531 - mae: 71.1562 - val_loss: 172922.6094 - val_mae: 76.3512\n",
      "Epoch 57/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 136044.6250 - mae: 70.6183 - val_loss: 156795.7500 - val_mae: 84.7451\n",
      "Epoch 58/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 148591.2969 - mae: 72.7355 - val_loss: 120105.4766 - val_mae: 64.9006\n",
      "Epoch 59/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 139878.5469 - mae: 70.7873 - val_loss: 130575.9688 - val_mae: 75.4352\n",
      "Epoch 60/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 156461.4375 - mae: 71.6402 - val_loss: 147664.9219 - val_mae: 90.0132\n",
      "Epoch 61/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: 135788.9375 - mae: 71.5312 - val_loss: 136836.1250 - val_mae: 76.4700\n",
      "Epoch 62/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 131559.8281 - mae: 68.8434 - val_loss: 140553.2188 - val_mae: 73.0150\n",
      "Epoch 63/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - loss: 141760.0625 - mae: 70.7064 - val_loss: 249347.5625 - val_mae: 110.3362\n",
      "Epoch 64/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 137012.0156 - mae: 71.8213 - val_loss: 244813.3438 - val_mae: 71.1979\n",
      "Epoch 65/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - loss: 130101.8125 - mae: 70.0740 - val_loss: 115611.3672 - val_mae: 62.8663\n",
      "Epoch 66/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 146687.2500 - mae: 70.7820 - val_loss: 144782.7500 - val_mae: 65.3841\n",
      "Epoch 67/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 142436.0781 - mae: 72.1394 - val_loss: 118081.0547 - val_mae: 70.7284\n",
      "Epoch 68/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 134675.8906 - mae: 70.6321 - val_loss: 113568.5234 - val_mae: 60.8782\n",
      "Epoch 69/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 139209.3594 - mae: 70.7109 - val_loss: 107336.9141 - val_mae: 59.4032\n",
      "Epoch 70/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 139959.0625 - mae: 71.2564 - val_loss: 117227.2734 - val_mae: 60.3017\n",
      "Epoch 71/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 138771.4531 - mae: 70.0499 - val_loss: 112539.7812 - val_mae: 56.0014\n",
      "Epoch 72/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 129203.9453 - mae: 68.3692 - val_loss: 130075.6328 - val_mae: 70.2619\n",
      "Epoch 73/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 132740.5938 - mae: 69.4353 - val_loss: 114006.6094 - val_mae: 59.3693\n",
      "Epoch 74/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 138333.4375 - mae: 69.2529 - val_loss: 125857.7344 - val_mae: 60.1217\n",
      "Epoch 75/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 134856.7344 - mae: 69.0880 - val_loss: 138136.0312 - val_mae: 83.1808\n",
      "Epoch 76/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 128904.1562 - mae: 68.2002 - val_loss: 140531.8438 - val_mae: 78.5279\n",
      "Epoch 77/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 127777.0000 - mae: 68.0764 - val_loss: 107090.6484 - val_mae: 66.5144\n",
      "Epoch 78/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 133793.3281 - mae: 69.3814 - val_loss: 115253.5156 - val_mae: 64.3814\n",
      "Epoch 79/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 127252.7344 - mae: 65.9011 - val_loss: 110071.6953 - val_mae: 61.1237\n",
      "Epoch 80/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 131431.0156 - mae: 66.8483 - val_loss: 136241.4688 - val_mae: 67.0570\n",
      "Epoch 81/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 133692.4062 - mae: 68.0061 - val_loss: 187460.7500 - val_mae: 84.8360\n",
      "Epoch 82/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 130083.3516 - mae: 67.1113 - val_loss: 185825.3281 - val_mae: 82.3120\n",
      "Epoch 83/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 130828.1641 - mae: 67.1411 - val_loss: 118845.7578 - val_mae: 63.4759\n",
      "Epoch 84/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 130315.6719 - mae: 67.2158 - val_loss: 132418.1875 - val_mae: 64.3842\n",
      "Epoch 85/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - loss: 134532.0000 - mae: 68.8312 - val_loss: 122670.0312 - val_mae: 70.0313\n",
      "Epoch 86/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3ms/step - loss: 132677.5625 - mae: 70.0496 - val_loss: 163264.7969 - val_mae: 70.9050\n",
      "Epoch 87/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - loss: 130267.4453 - mae: 66.8125 - val_loss: 123601.0469 - val_mae: 61.5637\n",
      "Epoch 88/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3ms/step - loss: 126007.0078 - mae: 66.1298 - val_loss: 110541.2266 - val_mae: 58.4858\n",
      "Epoch 89/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 135734.9688 - mae: 67.4690 - val_loss: 112038.1953 - val_mae: 61.8953\n",
      "Epoch 90/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 133270.5781 - mae: 67.6180 - val_loss: 115187.1094 - val_mae: 60.2737\n",
      "Epoch 91/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 130607.1406 - mae: 67.2614 - val_loss: 126080.9688 - val_mae: 65.7511\n",
      "Epoch 92/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 128488.1250 - mae: 65.7258 - val_loss: 116020.0078 - val_mae: 60.1691\n",
      "Epoch 93/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - loss: 121856.3203 - mae: 63.5519 - val_loss: 130014.6172 - val_mae: 58.3417\n",
      "Epoch 94/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - loss: 123256.9375 - mae: 65.0091 - val_loss: 196422.2500 - val_mae: 73.2998\n",
      "Epoch 95/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 126476.0156 - mae: 65.9015 - val_loss: 117529.0547 - val_mae: 60.1048\n",
      "Epoch 96/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 127627.7031 - mae: 65.3344 - val_loss: 115271.9609 - val_mae: 61.0170\n",
      "Epoch 97/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 143741.3594 - mae: 65.9297 - val_loss: 130697.9375 - val_mae: 63.2398\n",
      "Epoch 98/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 119504.3359 - mae: 63.8540 - val_loss: 114783.9297 - val_mae: 60.9457\n",
      "Epoch 99/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 130383.1406 - mae: 63.9103 - val_loss: 133439.5312 - val_mae: 67.8817\n",
      "Epoch 100/100\n",
      "\u001b[1m10017/10017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 124737.0547 - mae: 62.8638 - val_loss: 115321.3047 - val_mae: 68.0560\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.1,\n",
    "                    epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m loss, mae = \u001b[43mmodel\u001b[49m.evaluate(X_test, y_test, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Loss: {loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SemesterProject_AEMWE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
